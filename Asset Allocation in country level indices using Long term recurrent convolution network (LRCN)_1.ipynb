{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from datetime import datetime\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dm_index = pd.read_csv('/Users/r.shyaamprasadh/Downloads/Sample Data/dm_index.csv',sep=',',index_col=0)\n",
    "dm_pe = pd.read_csv('/Users/r.shyaamprasadh/Downloads/Sample Data/dm_pe.csv',sep=',',index_col=0)\n",
    "dm_pb = pd.read_csv('/Users/r.shyaamprasadh/Downloads/Sample Data/dm_pb.csv',sep=',',index_col=0)\n",
    "dm_ps = pd.read_csv('/Users/r.shyaamprasadh/Downloads/Sample Data/dm_ps.csv',sep=',',index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_index = pd.read_csv('/Users/r.shyaamprasadh/Downloads/Sample Data/em_index.csv',sep=',',index_col=0)\n",
    "em_pe = pd.read_csv('/Users/r.shyaamprasadh/Downloads/Sample Data/em_pe.csv',sep=',',index_col=0)\n",
    "em_pb = pd.read_csv('/Users/r.shyaamprasadh/Downloads/Sample Data/em_pb.csv',sep=',',index_col=0)\n",
    "em_ps = pd.read_csv('/Users/r.shyaamprasadh/Downloads/Sample Data/em_ps.csv',sep=',',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_returns = dm_index.shift(-22)/dm_index -1\n",
    "em_returns = em_index.shift(-22)/em_index -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Australia</th>\n",
       "      <th>Austria</th>\n",
       "      <th>Belgium</th>\n",
       "      <th>Canada</th>\n",
       "      <th>Denmark</th>\n",
       "      <th>Finland</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Hong Kong</th>\n",
       "      <th>Ireland</th>\n",
       "      <th>...</th>\n",
       "      <th>Netherlands</th>\n",
       "      <th>New Zealand</th>\n",
       "      <th>Norway</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Singapore</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Sweden</th>\n",
       "      <th>Switzerland</th>\n",
       "      <th>United Kingdom</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4/22/99</th>\n",
       "      <td>-0.038549</td>\n",
       "      <td>-0.049290</td>\n",
       "      <td>-0.020230</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.041047</td>\n",
       "      <td>-0.076975</td>\n",
       "      <td>0.029804</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>-0.026837</td>\n",
       "      <td>-0.055964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007909</td>\n",
       "      <td>-0.043698</td>\n",
       "      <td>-0.039064</td>\n",
       "      <td>0.016144</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>0.036972</td>\n",
       "      <td>0.030054</td>\n",
       "      <td>-0.016676</td>\n",
       "      <td>-0.031766</td>\n",
       "      <td>-0.039690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/23/99</th>\n",
       "      <td>-0.060999</td>\n",
       "      <td>-0.094688</td>\n",
       "      <td>-0.022170</td>\n",
       "      <td>-0.030230</td>\n",
       "      <td>0.044227</td>\n",
       "      <td>-0.048736</td>\n",
       "      <td>0.028191</td>\n",
       "      <td>-0.013074</td>\n",
       "      <td>-0.034386</td>\n",
       "      <td>-0.071613</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002061</td>\n",
       "      <td>-0.096779</td>\n",
       "      <td>-0.046556</td>\n",
       "      <td>0.012635</td>\n",
       "      <td>0.024811</td>\n",
       "      <td>0.019539</td>\n",
       "      <td>0.018183</td>\n",
       "      <td>-0.031558</td>\n",
       "      <td>-0.043465</td>\n",
       "      <td>-0.055487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/26/99</th>\n",
       "      <td>-0.063079</td>\n",
       "      <td>-0.100879</td>\n",
       "      <td>-0.043276</td>\n",
       "      <td>-0.039314</td>\n",
       "      <td>0.036735</td>\n",
       "      <td>-0.046693</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>-0.032891</td>\n",
       "      <td>-0.045502</td>\n",
       "      <td>-0.078464</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017178</td>\n",
       "      <td>-0.110196</td>\n",
       "      <td>-0.042651</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>0.011206</td>\n",
       "      <td>0.008148</td>\n",
       "      <td>-0.006712</td>\n",
       "      <td>-0.049313</td>\n",
       "      <td>-0.056325</td>\n",
       "      <td>-0.043005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/27/99</th>\n",
       "      <td>-0.074622</td>\n",
       "      <td>-0.106367</td>\n",
       "      <td>-0.071366</td>\n",
       "      <td>-0.048990</td>\n",
       "      <td>-0.001604</td>\n",
       "      <td>-0.077402</td>\n",
       "      <td>-0.027206</td>\n",
       "      <td>-0.078704</td>\n",
       "      <td>-0.077288</td>\n",
       "      <td>-0.103204</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052894</td>\n",
       "      <td>-0.114429</td>\n",
       "      <td>-0.056288</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.022153</td>\n",
       "      <td>-0.025643</td>\n",
       "      <td>-0.036017</td>\n",
       "      <td>-0.086381</td>\n",
       "      <td>-0.075438</td>\n",
       "      <td>-0.059511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/28/99</th>\n",
       "      <td>-0.074357</td>\n",
       "      <td>-0.116717</td>\n",
       "      <td>-0.062141</td>\n",
       "      <td>-0.040973</td>\n",
       "      <td>-0.018093</td>\n",
       "      <td>-0.042334</td>\n",
       "      <td>-0.026868</td>\n",
       "      <td>-0.068111</td>\n",
       "      <td>-0.071713</td>\n",
       "      <td>-0.125120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061152</td>\n",
       "      <td>-0.123910</td>\n",
       "      <td>-0.052332</td>\n",
       "      <td>-0.003539</td>\n",
       "      <td>0.047738</td>\n",
       "      <td>-0.014197</td>\n",
       "      <td>-0.031143</td>\n",
       "      <td>-0.075986</td>\n",
       "      <td>-0.067875</td>\n",
       "      <td>-0.036401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Australia   Austria   Belgium    Canada   Denmark   Finland  \\\n",
       "4/22/99  -0.038549 -0.049290 -0.020230  0.001701  0.041047 -0.076975   \n",
       "4/23/99  -0.060999 -0.094688 -0.022170 -0.030230  0.044227 -0.048736   \n",
       "4/26/99  -0.063079 -0.100879 -0.043276 -0.039314  0.036735 -0.046693   \n",
       "4/27/99  -0.074622 -0.106367 -0.071366 -0.048990 -0.001604 -0.077402   \n",
       "4/28/99  -0.074357 -0.116717 -0.062141 -0.040973 -0.018093 -0.042334   \n",
       "\n",
       "           France   Germany  Hong Kong   Ireland  ...  Netherlands  \\\n",
       "4/22/99  0.029804  0.001688  -0.026837 -0.055964  ...     0.007909   \n",
       "4/23/99  0.028191 -0.013074  -0.034386 -0.071613  ...    -0.002061   \n",
       "4/26/99  0.014634 -0.032891  -0.045502 -0.078464  ...    -0.017178   \n",
       "4/27/99 -0.027206 -0.078704  -0.077288 -0.103204  ...    -0.052894   \n",
       "4/28/99 -0.026868 -0.068111  -0.071713 -0.125120  ...    -0.061152   \n",
       "\n",
       "         New Zealand    Norway  Portugal  Singapore     Spain    Sweden  \\\n",
       "4/22/99    -0.043698 -0.039064  0.016144   0.052100  0.036972  0.030054   \n",
       "4/23/99    -0.096779 -0.046556  0.012635   0.024811  0.019539  0.018183   \n",
       "4/26/99    -0.110196 -0.042651  0.010686   0.011206  0.008148 -0.006712   \n",
       "4/27/99    -0.114429 -0.056288  0.000958   0.022153 -0.025643 -0.036017   \n",
       "4/28/99    -0.123910 -0.052332 -0.003539   0.047738 -0.014197 -0.031143   \n",
       "\n",
       "         Switzerland  United Kingdom       USA  \n",
       "4/22/99    -0.016676       -0.031766 -0.039690  \n",
       "4/23/99    -0.031558       -0.043465 -0.055487  \n",
       "4/26/99    -0.049313       -0.056325 -0.043005  \n",
       "4/27/99    -0.086381       -0.075438 -0.059511  \n",
       "4/28/99    -0.075986       -0.067875 -0.036401  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm_returns.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5196, 23)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm_returns = dm_returns.dropna()\n",
    "dm_returns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EM (Emerging Markets)</th>\n",
       "      <th>China</th>\n",
       "      <th>India</th>\n",
       "      <th>Indonesia</th>\n",
       "      <th>Korea</th>\n",
       "      <th>Malaysia -EM</th>\n",
       "      <th>Pakistan</th>\n",
       "      <th>Philippines</th>\n",
       "      <th>Sri Lanka</th>\n",
       "      <th>Taiwan</th>\n",
       "      <th>...</th>\n",
       "      <th>Egypt</th>\n",
       "      <th>Greece</th>\n",
       "      <th>Hungary</th>\n",
       "      <th>Poland</th>\n",
       "      <th>Qatar</th>\n",
       "      <th>Russia</th>\n",
       "      <th>Russia ADR/GDR Index</th>\n",
       "      <th>South Africa</th>\n",
       "      <th>Turkey</th>\n",
       "      <th>United Arab Emirates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4/15/99</th>\n",
       "      <td>0.088020</td>\n",
       "      <td>0.164491</td>\n",
       "      <td>0.207849</td>\n",
       "      <td>0.478506</td>\n",
       "      <td>0.033282</td>\n",
       "      <td>0.363094</td>\n",
       "      <td>0.218559</td>\n",
       "      <td>0.092153</td>\n",
       "      <td>-0.011290</td>\n",
       "      <td>-0.014202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013484</td>\n",
       "      <td>0.065111</td>\n",
       "      <td>0.103190</td>\n",
       "      <td>0.076204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.266419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.042092</td>\n",
       "      <td>0.222676</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/16/99</th>\n",
       "      <td>0.075693</td>\n",
       "      <td>0.137080</td>\n",
       "      <td>0.147163</td>\n",
       "      <td>0.341103</td>\n",
       "      <td>0.042655</td>\n",
       "      <td>0.348395</td>\n",
       "      <td>0.229328</td>\n",
       "      <td>0.066936</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>-0.023790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>0.136219</td>\n",
       "      <td>0.110324</td>\n",
       "      <td>0.091773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.308283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.062246</td>\n",
       "      <td>0.203267</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/19/99</th>\n",
       "      <td>0.052199</td>\n",
       "      <td>0.102633</td>\n",
       "      <td>0.201043</td>\n",
       "      <td>0.301372</td>\n",
       "      <td>-0.034310</td>\n",
       "      <td>0.299177</td>\n",
       "      <td>0.227341</td>\n",
       "      <td>-0.025652</td>\n",
       "      <td>0.006101</td>\n",
       "      <td>-0.048632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015093</td>\n",
       "      <td>0.205412</td>\n",
       "      <td>0.118972</td>\n",
       "      <td>0.081435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.211721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.095692</td>\n",
       "      <td>0.215847</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/20/99</th>\n",
       "      <td>0.052090</td>\n",
       "      <td>0.049777</td>\n",
       "      <td>0.186168</td>\n",
       "      <td>0.339287</td>\n",
       "      <td>-0.075789</td>\n",
       "      <td>0.289750</td>\n",
       "      <td>0.217920</td>\n",
       "      <td>-0.041225</td>\n",
       "      <td>0.047975</td>\n",
       "      <td>-0.045171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021414</td>\n",
       "      <td>0.213831</td>\n",
       "      <td>0.083994</td>\n",
       "      <td>0.052866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.244424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.085205</td>\n",
       "      <td>0.079457</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/21/99</th>\n",
       "      <td>0.055375</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>0.158132</td>\n",
       "      <td>0.357532</td>\n",
       "      <td>-0.028749</td>\n",
       "      <td>0.283130</td>\n",
       "      <td>0.214858</td>\n",
       "      <td>-0.016460</td>\n",
       "      <td>0.055243</td>\n",
       "      <td>-0.022395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.226454</td>\n",
       "      <td>0.072688</td>\n",
       "      <td>0.079040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.288111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.055005</td>\n",
       "      <td>0.064506</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         EM (Emerging Markets)     China     India  Indonesia     Korea  \\\n",
       "4/15/99               0.088020  0.164491  0.207849   0.478506  0.033282   \n",
       "4/16/99               0.075693  0.137080  0.147163   0.341103  0.042655   \n",
       "4/19/99               0.052199  0.102633  0.201043   0.301372 -0.034310   \n",
       "4/20/99               0.052090  0.049777  0.186168   0.339287 -0.075789   \n",
       "4/21/99               0.055375  0.006688  0.158132   0.357532 -0.028749   \n",
       "\n",
       "         Malaysia -EM  Pakistan  Philippines  Sri Lanka    Taiwan  ...  \\\n",
       "4/15/99      0.363094  0.218559     0.092153  -0.011290 -0.014202  ...   \n",
       "4/16/99      0.348395  0.229328     0.066936   0.003008 -0.023790  ...   \n",
       "4/19/99      0.299177  0.227341    -0.025652   0.006101 -0.048632  ...   \n",
       "4/20/99      0.289750  0.217920    -0.041225   0.047975 -0.045171  ...   \n",
       "4/21/99      0.283130  0.214858    -0.016460   0.055243 -0.022395  ...   \n",
       "\n",
       "            Egypt    Greece   Hungary    Poland  Qatar    Russia  \\\n",
       "4/15/99  0.013484  0.065111  0.103190  0.076204    NaN  0.266419   \n",
       "4/16/99  0.006389  0.136219  0.110324  0.091773    NaN  0.308283   \n",
       "4/19/99  0.015093  0.205412  0.118972  0.081435    NaN  0.211721   \n",
       "4/20/99  0.021414  0.213831  0.083994  0.052866    NaN  0.244424   \n",
       "4/21/99  0.002499  0.226454  0.072688  0.079040    NaN  0.288111   \n",
       "\n",
       "         Russia ADR/GDR Index  South Africa    Turkey  United Arab Emirates  \n",
       "4/15/99                   NaN     -0.042092  0.222676                   NaN  \n",
       "4/16/99                   NaN     -0.062246  0.203267                   NaN  \n",
       "4/19/99                   NaN     -0.095692  0.215847                   NaN  \n",
       "4/20/99                   NaN     -0.085205  0.079457                   NaN  \n",
       "4/21/99                   NaN     -0.055005  0.064506                   NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_returns.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5218, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_returns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_dm_returns = dm_returns.apply(lambda x:(x-x.min()) / (x.max()-x.min()),axis=1)\n",
    "scaled_dm_pe = dm_pe.apply(lambda x:(x-x.min()) / (x.max()-x.min()),axis=1)\n",
    "scaled_dm_pb = dm_pb.apply(lambda x:(x-x.min()) / (x.max()-x.min()),axis=1)\n",
    "scaled_dm_ps = dm_ps.apply(lambda x:(x-x.min()) / (x.max()-x.min()),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Australia</th>\n",
       "      <th>Austria</th>\n",
       "      <th>Belgium</th>\n",
       "      <th>Canada</th>\n",
       "      <th>Denmark</th>\n",
       "      <th>Finland</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Hong Kong</th>\n",
       "      <th>Ireland</th>\n",
       "      <th>...</th>\n",
       "      <th>Netherlands</th>\n",
       "      <th>New Zealand</th>\n",
       "      <th>Norway</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Singapore</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Sweden</th>\n",
       "      <th>Switzerland</th>\n",
       "      <th>United Kingdom</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5196.000000</td>\n",
       "      <td>5196.000000</td>\n",
       "      <td>5196.000000</td>\n",
       "      <td>5196.000000</td>\n",
       "      <td>5196.000000</td>\n",
       "      <td>5196.000000</td>\n",
       "      <td>5196.000000</td>\n",
       "      <td>5196.000000</td>\n",
       "      <td>5196.000000</td>\n",
       "      <td>5196.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5196.000000</td>\n",
       "      <td>5196.000000</td>\n",
       "      <td>5196.000000</td>\n",
       "      <td>5196.000000</td>\n",
       "      <td>5196.000000</td>\n",
       "      <td>5196.000000</td>\n",
       "      <td>5196.000000</td>\n",
       "      <td>5196.000000</td>\n",
       "      <td>5196.000000</td>\n",
       "      <td>5196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.510528</td>\n",
       "      <td>0.516806</td>\n",
       "      <td>0.503445</td>\n",
       "      <td>0.517395</td>\n",
       "      <td>0.546396</td>\n",
       "      <td>0.509907</td>\n",
       "      <td>0.502887</td>\n",
       "      <td>0.505509</td>\n",
       "      <td>0.513686</td>\n",
       "      <td>0.480101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506677</td>\n",
       "      <td>0.500291</td>\n",
       "      <td>0.523230</td>\n",
       "      <td>0.475275</td>\n",
       "      <td>0.511719</td>\n",
       "      <td>0.492303</td>\n",
       "      <td>0.515150</td>\n",
       "      <td>0.510747</td>\n",
       "      <td>0.484296</td>\n",
       "      <td>0.506631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.237797</td>\n",
       "      <td>0.295270</td>\n",
       "      <td>0.258685</td>\n",
       "      <td>0.241061</td>\n",
       "      <td>0.244424</td>\n",
       "      <td>0.309542</td>\n",
       "      <td>0.174940</td>\n",
       "      <td>0.213300</td>\n",
       "      <td>0.271350</td>\n",
       "      <td>0.290868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208305</td>\n",
       "      <td>0.305015</td>\n",
       "      <td>0.292843</td>\n",
       "      <td>0.277764</td>\n",
       "      <td>0.269990</td>\n",
       "      <td>0.266228</td>\n",
       "      <td>0.241171</td>\n",
       "      <td>0.214029</td>\n",
       "      <td>0.186798</td>\n",
       "      <td>0.230975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.343910</td>\n",
       "      <td>0.283861</td>\n",
       "      <td>0.316608</td>\n",
       "      <td>0.349611</td>\n",
       "      <td>0.376502</td>\n",
       "      <td>0.281869</td>\n",
       "      <td>0.373302</td>\n",
       "      <td>0.369199</td>\n",
       "      <td>0.315957</td>\n",
       "      <td>0.254594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365172</td>\n",
       "      <td>0.266515</td>\n",
       "      <td>0.305914</td>\n",
       "      <td>0.266657</td>\n",
       "      <td>0.321063</td>\n",
       "      <td>0.306044</td>\n",
       "      <td>0.347995</td>\n",
       "      <td>0.352270</td>\n",
       "      <td>0.359801</td>\n",
       "      <td>0.339449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.514394</td>\n",
       "      <td>0.508148</td>\n",
       "      <td>0.506915</td>\n",
       "      <td>0.516211</td>\n",
       "      <td>0.541848</td>\n",
       "      <td>0.519303</td>\n",
       "      <td>0.500434</td>\n",
       "      <td>0.507092</td>\n",
       "      <td>0.516227</td>\n",
       "      <td>0.476563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507337</td>\n",
       "      <td>0.497031</td>\n",
       "      <td>0.524943</td>\n",
       "      <td>0.476570</td>\n",
       "      <td>0.515482</td>\n",
       "      <td>0.490125</td>\n",
       "      <td>0.514823</td>\n",
       "      <td>0.516534</td>\n",
       "      <td>0.481272</td>\n",
       "      <td>0.498388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.685000</td>\n",
       "      <td>0.754990</td>\n",
       "      <td>0.695754</td>\n",
       "      <td>0.689033</td>\n",
       "      <td>0.722138</td>\n",
       "      <td>0.740555</td>\n",
       "      <td>0.629374</td>\n",
       "      <td>0.641071</td>\n",
       "      <td>0.709307</td>\n",
       "      <td>0.703860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653258</td>\n",
       "      <td>0.737534</td>\n",
       "      <td>0.747066</td>\n",
       "      <td>0.669500</td>\n",
       "      <td>0.710168</td>\n",
       "      <td>0.676015</td>\n",
       "      <td>0.680484</td>\n",
       "      <td>0.667035</td>\n",
       "      <td>0.613878</td>\n",
       "      <td>0.672532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Australia      Austria      Belgium       Canada      Denmark  \\\n",
       "count  5196.000000  5196.000000  5196.000000  5196.000000  5196.000000   \n",
       "mean      0.510528     0.516806     0.503445     0.517395     0.546396   \n",
       "std       0.237797     0.295270     0.258685     0.241061     0.244424   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.343910     0.283861     0.316608     0.349611     0.376502   \n",
       "50%       0.514394     0.508148     0.506915     0.516211     0.541848   \n",
       "75%       0.685000     0.754990     0.695754     0.689033     0.722138   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "           Finland       France      Germany    Hong Kong      Ireland  ...  \\\n",
       "count  5196.000000  5196.000000  5196.000000  5196.000000  5196.000000  ...   \n",
       "mean      0.509907     0.502887     0.505509     0.513686     0.480101  ...   \n",
       "std       0.309542     0.174940     0.213300     0.271350     0.290868  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.281869     0.373302     0.369199     0.315957     0.254594  ...   \n",
       "50%       0.519303     0.500434     0.507092     0.516227     0.476563  ...   \n",
       "75%       0.740555     0.629374     0.641071     0.709307     0.703860  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "       Netherlands  New Zealand       Norway     Portugal    Singapore  \\\n",
       "count  5196.000000  5196.000000  5196.000000  5196.000000  5196.000000   \n",
       "mean      0.506677     0.500291     0.523230     0.475275     0.511719   \n",
       "std       0.208305     0.305015     0.292843     0.277764     0.269990   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.365172     0.266515     0.305914     0.266657     0.321063   \n",
       "50%       0.507337     0.497031     0.524943     0.476570     0.515482   \n",
       "75%       0.653258     0.737534     0.747066     0.669500     0.710168   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             Spain       Sweden  Switzerland  United Kingdom          USA  \n",
       "count  5196.000000  5196.000000  5196.000000     5196.000000  5196.000000  \n",
       "mean      0.492303     0.515150     0.510747        0.484296     0.506631  \n",
       "std       0.266228     0.241171     0.214029        0.186798     0.230975  \n",
       "min       0.000000     0.000000     0.000000        0.000000     0.000000  \n",
       "25%       0.306044     0.347995     0.352270        0.359801     0.339449  \n",
       "50%       0.490125     0.514823     0.516534        0.481272     0.498388  \n",
       "75%       0.676015     0.680484     0.667035        0.613878     0.672532  \n",
       "max       1.000000     1.000000     1.000000        1.000000     1.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_dm_returns.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Australia</th>\n",
       "      <th>Austria</th>\n",
       "      <th>Belgium</th>\n",
       "      <th>Canada</th>\n",
       "      <th>Denmark</th>\n",
       "      <th>Finland</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Hong Kong</th>\n",
       "      <th>Ireland</th>\n",
       "      <th>...</th>\n",
       "      <th>Netherlands</th>\n",
       "      <th>New Zealand</th>\n",
       "      <th>Norway</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Singapore</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Sweden</th>\n",
       "      <th>Switzerland</th>\n",
       "      <th>United Kingdom</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5218.000000</td>\n",
       "      <td>5218.000000</td>\n",
       "      <td>5218.000000</td>\n",
       "      <td>5218.000000</td>\n",
       "      <td>5218.000000</td>\n",
       "      <td>5218.000000</td>\n",
       "      <td>5218.000000</td>\n",
       "      <td>5218.000000</td>\n",
       "      <td>5218.000000</td>\n",
       "      <td>5218.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5218.000000</td>\n",
       "      <td>5218.000000</td>\n",
       "      <td>5218.000000</td>\n",
       "      <td>5218.000000</td>\n",
       "      <td>5218.000000</td>\n",
       "      <td>5218.000000</td>\n",
       "      <td>5218.000000</td>\n",
       "      <td>5218.000000</td>\n",
       "      <td>5218.000000</td>\n",
       "      <td>5218.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.411331</td>\n",
       "      <td>0.159838</td>\n",
       "      <td>0.354406</td>\n",
       "      <td>0.456740</td>\n",
       "      <td>0.540571</td>\n",
       "      <td>0.587247</td>\n",
       "      <td>0.318047</td>\n",
       "      <td>0.272337</td>\n",
       "      <td>0.544619</td>\n",
       "      <td>0.489200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337241</td>\n",
       "      <td>0.405485</td>\n",
       "      <td>0.174063</td>\n",
       "      <td>0.347455</td>\n",
       "      <td>0.410551</td>\n",
       "      <td>0.271384</td>\n",
       "      <td>0.490359</td>\n",
       "      <td>0.509185</td>\n",
       "      <td>0.288315</td>\n",
       "      <td>0.524726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.126077</td>\n",
       "      <td>0.140966</td>\n",
       "      <td>0.291747</td>\n",
       "      <td>0.140012</td>\n",
       "      <td>0.251450</td>\n",
       "      <td>0.198562</td>\n",
       "      <td>0.160636</td>\n",
       "      <td>0.164514</td>\n",
       "      <td>0.240229</td>\n",
       "      <td>0.340505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183532</td>\n",
       "      <td>0.395235</td>\n",
       "      <td>0.156321</td>\n",
       "      <td>0.192992</td>\n",
       "      <td>0.187809</td>\n",
       "      <td>0.153029</td>\n",
       "      <td>0.155519</td>\n",
       "      <td>0.177357</td>\n",
       "      <td>0.158192</td>\n",
       "      <td>0.170280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.020389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018967</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027269</td>\n",
       "      <td>0.020554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.338160</td>\n",
       "      <td>0.056347</td>\n",
       "      <td>0.112314</td>\n",
       "      <td>0.365492</td>\n",
       "      <td>0.383277</td>\n",
       "      <td>0.462691</td>\n",
       "      <td>0.197939</td>\n",
       "      <td>0.162445</td>\n",
       "      <td>0.355835</td>\n",
       "      <td>0.233282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192285</td>\n",
       "      <td>0.019377</td>\n",
       "      <td>0.057432</td>\n",
       "      <td>0.205567</td>\n",
       "      <td>0.273814</td>\n",
       "      <td>0.174601</td>\n",
       "      <td>0.380617</td>\n",
       "      <td>0.390423</td>\n",
       "      <td>0.179738</td>\n",
       "      <td>0.413746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.411528</td>\n",
       "      <td>0.131799</td>\n",
       "      <td>0.268565</td>\n",
       "      <td>0.460910</td>\n",
       "      <td>0.564053</td>\n",
       "      <td>0.574699</td>\n",
       "      <td>0.288107</td>\n",
       "      <td>0.222584</td>\n",
       "      <td>0.497361</td>\n",
       "      <td>0.382518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337400</td>\n",
       "      <td>0.263249</td>\n",
       "      <td>0.130005</td>\n",
       "      <td>0.321032</td>\n",
       "      <td>0.395961</td>\n",
       "      <td>0.273108</td>\n",
       "      <td>0.478184</td>\n",
       "      <td>0.506051</td>\n",
       "      <td>0.267253</td>\n",
       "      <td>0.511067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.491645</td>\n",
       "      <td>0.231213</td>\n",
       "      <td>0.530622</td>\n",
       "      <td>0.545650</td>\n",
       "      <td>0.722233</td>\n",
       "      <td>0.716820</td>\n",
       "      <td>0.413358</td>\n",
       "      <td>0.353015</td>\n",
       "      <td>0.696318</td>\n",
       "      <td>0.809118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468536</td>\n",
       "      <td>0.853723</td>\n",
       "      <td>0.254430</td>\n",
       "      <td>0.452194</td>\n",
       "      <td>0.526348</td>\n",
       "      <td>0.380257</td>\n",
       "      <td>0.591694</td>\n",
       "      <td>0.627290</td>\n",
       "      <td>0.400288</td>\n",
       "      <td>0.657371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.987484</td>\n",
       "      <td>0.980165</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993072</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983170</td>\n",
       "      <td>0.982485</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981815</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981072</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980201</td>\n",
       "      <td>0.993306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981594</td>\n",
       "      <td>0.987581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Australia      Austria      Belgium       Canada      Denmark  \\\n",
       "count  5218.000000  5218.000000  5218.000000  5218.000000  5218.000000   \n",
       "mean      0.411331     0.159838     0.354406     0.456740     0.540571   \n",
       "std       0.126077     0.140966     0.291747     0.140012     0.251450   \n",
       "min       0.020389     0.000000     0.000000     0.021544     0.000000   \n",
       "25%       0.338160     0.056347     0.112314     0.365492     0.383277   \n",
       "50%       0.411528     0.131799     0.268565     0.460910     0.564053   \n",
       "75%       0.491645     0.231213     0.530622     0.545650     0.722233   \n",
       "max       0.987484     0.980165     1.000000     0.993072     1.000000   \n",
       "\n",
       "           Finland       France      Germany    Hong Kong      Ireland  ...  \\\n",
       "count  5218.000000  5218.000000  5218.000000  5218.000000  5218.000000  ...   \n",
       "mean      0.587247     0.318047     0.272337     0.544619     0.489200  ...   \n",
       "std       0.198562     0.160636     0.164514     0.240229     0.340505  ...   \n",
       "min       0.018967     0.014085     0.000000     0.031085     0.000000  ...   \n",
       "25%       0.462691     0.197939     0.162445     0.355835     0.233282  ...   \n",
       "50%       0.574699     0.288107     0.222584     0.497361     0.382518  ...   \n",
       "75%       0.716820     0.413358     0.353015     0.696318     0.809118  ...   \n",
       "max       1.000000     0.983170     0.982485     1.000000     1.000000  ...   \n",
       "\n",
       "       Netherlands  New Zealand       Norway     Portugal    Singapore  \\\n",
       "count  5218.000000  5218.000000  5218.000000  5218.000000  5218.000000   \n",
       "mean      0.337241     0.405485     0.174063     0.347455     0.410551   \n",
       "std       0.183532     0.395235     0.156321     0.192992     0.187809   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.192285     0.019377     0.057432     0.205567     0.273814   \n",
       "50%       0.337400     0.263249     0.130005     0.321032     0.395961   \n",
       "75%       0.468536     0.853723     0.254430     0.452194     0.526348   \n",
       "max       0.981815     1.000000     0.981072     1.000000     1.000000   \n",
       "\n",
       "             Spain       Sweden  Switzerland  United Kingdom          USA  \n",
       "count  5218.000000  5218.000000  5218.000000     5218.000000  5218.000000  \n",
       "mean      0.271384     0.490359     0.509185        0.288315     0.524726  \n",
       "std       0.153029     0.155519     0.177357        0.158192     0.170280  \n",
       "min       0.000000     0.027269     0.020554        0.000000     0.022811  \n",
       "25%       0.174601     0.380617     0.390423        0.179738     0.413746  \n",
       "50%       0.273108     0.478184     0.506051        0.267253     0.511067  \n",
       "75%       0.380257     0.591694     0.627290        0.400288     0.657371  \n",
       "max       0.980201     0.993306     1.000000        0.981594     0.987581  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_dm_pe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5218, 23)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_dm_pe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_dm_pe = scaled_dm_pe[scaled_dm_pe.index.isin(scaled_dm_returns.index)]\n",
    "scaled_dm_pb = scaled_dm_pb[scaled_dm_pb.index.isin(scaled_dm_returns.index)]\n",
    "scaled_dm_ps = scaled_dm_ps[scaled_dm_ps.index.isin(scaled_dm_returns.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5196, 23), (5196, 23))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_dm_returns.shape,scaled_dm_pe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(scaled_dm_returns['USA'],color='blue',kde=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the sequence \n",
    "def create_dataset(df1, df2, df3, df4, colidx):\n",
    "    df1 = np.array(df1.iloc[:,colidx])\n",
    "    df1 = df1.reshape((len(df1),1))\n",
    "    df2 = np.array(df2.iloc[:,colidx])\n",
    "    df2 = df2.reshape((len(df2),1))\n",
    "    df3 = np.array(df3.iloc[:,colidx])\n",
    "    df3 = df3.reshape((len(df3),1))\n",
    "    df4 = np.array(df4.iloc[:,colidx])\n",
    "    df4 = df4.reshape((len(df4),1))\n",
    "    dataset = np.hstack((df1,df2,df3,df4,df4))\n",
    "    splitpnt = len(dataset) *2 //3\n",
    "    train_data = dataset[:splitpnt,:]\n",
    "    val_data = dataset[splitpnt+1:,:]\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "n_steps = 22\n",
    "n_features = 4\n",
    "n_seq = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(20, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-LSTM-Australia.json\n",
      "Epoch 1/150\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 2/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 3/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 4/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 5/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 6/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 7/150\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 8/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 9/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 10/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 11/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 12/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 13/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 14/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 15/150\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 16/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 17/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 18/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 19/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 20/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 21/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 22/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 23/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 24/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 25/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 26/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 27/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 28/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 29/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 30/150\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 31/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 32/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 33/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 34/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 35/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 36/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 37/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 38/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 39/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 40/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 41/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 42/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 43/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 44/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 45/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 46/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 47/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 48/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 49/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 50/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 51/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 52/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 53/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 54/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 55/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 56/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 57/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 58/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 59/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 60/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 61/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 62/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 63/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 64/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 65/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 66/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 67/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0062\n",
      "Epoch 68/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 69/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 70/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 71/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 72/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 73/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0079\n",
      "Epoch 74/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0068\n",
      "Epoch 75/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0070\n",
      "Epoch 76/150\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0058\n",
      "Epoch 77/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 78/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0063\n",
      "Epoch 79/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 80/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0073\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0100\n",
      "Epoch 82/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0083\n",
      "Epoch 83/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0068\n",
      "Epoch 84/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0094\n",
      "Epoch 85/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0092\n",
      "Epoch 86/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0096\n",
      "Epoch 87/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0084\n",
      "Epoch 88/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0085\n",
      "Epoch 89/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0119\n",
      "Epoch 90/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0113\n",
      "Epoch 91/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0091\n",
      "Epoch 92/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0153\n",
      "Epoch 93/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0127\n",
      "Epoch 94/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0101\n",
      "Epoch 95/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0126\n",
      "Epoch 96/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0145\n",
      "Epoch 97/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0110\n",
      "Epoch 98/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0134\n",
      "Epoch 99/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0123\n",
      "Epoch 100/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0085\n",
      "Epoch 101/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0097\n",
      "Epoch 102/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0116\n",
      "Epoch 103/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0127\n",
      "Epoch 104/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0166\n",
      "Epoch 105/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0156\n",
      "Epoch 106/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0228\n",
      "Epoch 107/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0101\n",
      "Epoch 108/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0160\n",
      "Epoch 109/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0179\n",
      "Epoch 110/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0142\n",
      "Epoch 111/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0205\n",
      "Epoch 112/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0277\n",
      "Epoch 113/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0168\n",
      "Epoch 114/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0235\n",
      "Epoch 115/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0243\n",
      "Epoch 116/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0190\n",
      "Epoch 117/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0173\n",
      "Epoch 118/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0188\n",
      "Epoch 119/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0174\n",
      "Epoch 120/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0237\n",
      "Epoch 121/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0141\n",
      "Epoch 122/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0210\n",
      "Epoch 123/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0291\n",
      "Epoch 124/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0190\n",
      "Epoch 125/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0267\n",
      "Epoch 126/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0286\n",
      "Epoch 127/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0243\n",
      "Epoch 128/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0183\n",
      "Epoch 129/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0270\n",
      "Epoch 130/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0208\n",
      "Epoch 131/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0273\n",
      "Epoch 132/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0399\n",
      "Epoch 133/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0268\n",
      "Epoch 134/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0294\n",
      "Epoch 135/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0265\n",
      "Epoch 136/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0209\n",
      "Epoch 137/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0261\n",
      "Epoch 138/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0300\n",
      "Epoch 139/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0351\n",
      "Epoch 140/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0235\n",
      "Epoch 141/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0286\n",
      "Epoch 142/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0141\n",
      "Epoch 143/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0269\n",
      "Epoch 144/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0294\n",
      "Epoch 145/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0293\n",
      "Epoch 146/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0281\n",
      "Epoch 147/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0224\n",
      "Epoch 148/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0396\n",
      "Epoch 149/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0201\n",
      "Epoch 150/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0316\n",
      "Epoch 1/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0399\n",
      "Epoch 2/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0467\n",
      "Epoch 3/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0520\n",
      "Epoch 4/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0343\n",
      "Epoch 5/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0394\n",
      "Epoch 6/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0482\n",
      "Epoch 7/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0460\n",
      "Epoch 8/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0374\n",
      "Epoch 9/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0312\n",
      "Epoch 10/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0365\n",
      "Epoch 11/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0251\n",
      "Epoch 12/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0366\n",
      "Epoch 13/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0254\n",
      "Epoch 14/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0282\n",
      "Epoch 15/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0301\n",
      "Epoch 16/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0299\n",
      "Epoch 17/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0343\n",
      "Epoch 18/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0257\n",
      "Epoch 19/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0314\n",
      "Epoch 20/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0415\n",
      "Epoch 21/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0369\n",
      "Epoch 22/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0350\n",
      "Epoch 23/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0328\n",
      "Epoch 24/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0334\n",
      "Epoch 25/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0607\n",
      "Epoch 26/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0417\n",
      "Epoch 27/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0477\n",
      "Epoch 28/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0580\n",
      "Epoch 29/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0532\n",
      "Epoch 30/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0361\n",
      "Epoch 31/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0407\n",
      "Epoch 32/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0502\n",
      "Epoch 33/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0515\n",
      "Epoch 34/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0483\n",
      "Epoch 35/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0376\n",
      "Epoch 36/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0354\n",
      "Epoch 37/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0440\n",
      "Epoch 38/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0510\n",
      "Epoch 39/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0422\n",
      "Epoch 40/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0605\n",
      "Epoch 41/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0431\n",
      "Epoch 42/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0378\n",
      "Epoch 43/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0504\n",
      "Epoch 44/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0581\n",
      "Epoch 45/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0364\n",
      "Epoch 46/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0469\n",
      "Epoch 47/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0677\n",
      "Epoch 48/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0591\n",
      "Epoch 49/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0422\n",
      "Epoch 50/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0603\n",
      "Epoch 51/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0526\n",
      "Epoch 52/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0264\n",
      "Epoch 53/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0416\n",
      "Epoch 54/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0438\n",
      "Epoch 55/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0491\n",
      "Epoch 56/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0517\n",
      "Epoch 57/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0749\n",
      "Epoch 58/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0419\n",
      "Epoch 59/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0554\n",
      "Epoch 60/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0452\n",
      "Epoch 61/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0589\n",
      "Epoch 62/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0705\n",
      "Epoch 63/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0635\n",
      "Epoch 64/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0505\n",
      "Epoch 65/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0708\n",
      "Epoch 66/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0608\n",
      "Epoch 67/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0530\n",
      "Epoch 68/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0429\n",
      "Epoch 69/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0439\n",
      "Epoch 70/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0467\n",
      "Epoch 71/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0443\n",
      "Epoch 72/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0488\n",
      "Epoch 73/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0774\n",
      "Epoch 74/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0615\n",
      "Epoch 75/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0609\n",
      "Epoch 76/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0692\n",
      "Epoch 77/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0614\n",
      "Epoch 78/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0599\n",
      "Epoch 79/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0655\n",
      "Epoch 80/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0718\n",
      "Epoch 81/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0489\n",
      "Epoch 82/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0722\n",
      "Epoch 83/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0875\n",
      "Epoch 84/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0596\n",
      "Epoch 85/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0479\n",
      "Epoch 86/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0547\n",
      "Epoch 87/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0668\n",
      "Epoch 88/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0596\n",
      "Epoch 89/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0449\n",
      "Epoch 90/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0451\n",
      "Epoch 91/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0700\n",
      "Epoch 92/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0801\n",
      "Epoch 93/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0779\n",
      "Epoch 94/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0580\n",
      "Epoch 95/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0505\n",
      "Epoch 96/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0571\n",
      "Epoch 97/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0741\n",
      "Epoch 98/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0752\n",
      "Epoch 99/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0709\n",
      "Epoch 100/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0562\n",
      "Epoch 101/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0445\n",
      "Epoch 102/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0660\n",
      "Epoch 103/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0540\n",
      "Epoch 104/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0732\n",
      "Epoch 105/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0574\n",
      "Epoch 106/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0579\n",
      "Epoch 107/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0741\n",
      "Epoch 108/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0557\n",
      "Epoch 109/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0590\n",
      "Epoch 110/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0509\n",
      "Epoch 111/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0956\n",
      "Epoch 112/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0544\n",
      "Epoch 113/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0553\n",
      "Epoch 114/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0670\n",
      "Epoch 115/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0677\n",
      "Epoch 116/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0677\n",
      "Epoch 117/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0417\n",
      "Epoch 118/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0612\n",
      "Epoch 119/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0882\n",
      "Epoch 120/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0645\n",
      "Epoch 121/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0469\n",
      "Epoch 122/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0712\n",
      "Epoch 123/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0641\n",
      "Epoch 124/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0625\n",
      "Epoch 125/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0622\n",
      "Epoch 126/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0630\n",
      "Epoch 127/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0514\n",
      "Epoch 128/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0505\n",
      "Epoch 129/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0626\n",
      "Epoch 130/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0757\n",
      "Epoch 131/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0514\n",
      "Epoch 132/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0505\n",
      "Epoch 133/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0516\n",
      "Epoch 134/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0422\n",
      "Epoch 135/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0658\n",
      "Epoch 136/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0532\n",
      "Epoch 137/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0620\n",
      "Epoch 138/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0514\n",
      "Epoch 139/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0495\n",
      "Epoch 140/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0567\n",
      "Epoch 141/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0406\n",
      "Epoch 142/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0574\n",
      "Epoch 143/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0585\n",
      "Epoch 144/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0420\n",
      "Epoch 145/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0391\n",
      "Epoch 146/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0457\n",
      "Epoch 147/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0530\n",
      "Epoch 148/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0617\n",
      "Epoch 149/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0658\n",
      "Epoch 150/150\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0409\n",
      "Australia done\n"
     ]
    }
   ],
   "source": [
    "    !rm -rf ./logs/\n",
    "\n",
    "    n=23#change the values to get loss for each country\n",
    "    i = scaled_dm_returns.shape[1]-n\n",
    "    t, v = create_dataset(scaled_dm_pe, scaled_dm_pb, scaled_dm_ps, scaled_dm_returns, i)\n",
    "    tx, ty = split_sequences(t, n_steps)\n",
    "    vx, vy = split_sequences(v, n_steps)\n",
    "    tx = tx.reshape((tx.shape[0], n_seq, n_steps, n_features))\n",
    "    vx = vx.reshape((vx.shape[0], n_seq, n_steps, n_features))\n",
    "    filename = 'CNN-LSTM-' + scaled_dm_returns.columns[i] +'.json'\n",
    "    print(filename)\n",
    "    model.fit(tx,ty,epochs=150, validation_data=(vx, vy),callbacks=[tensorboard_callback])\n",
    "    history = model.fit(tx,ty,epochs=150, validation_data=(vx, vy))\n",
    "    pyplot.plot(history.history['loss'])\n",
    "    pyplot.plot(history.history['val_loss'])\n",
    "    pyplot.title('model train vs validation loss for ' + scaled_dm_returns.columns[i])\n",
    "    pyplot.ylabel('loss')\n",
    "    pyplot.xlabel('epoch')\n",
    "    pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "    pyplot.savefig(('CNN-LSTM-' + scaled_dm_returns.columns[i] + '.png'))\n",
    "    pyplot.close()\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    print(scaled_dm_returns.columns[i] + ' done')\n",
    "    with open(filename, mode='w') as f:\n",
    "        hist_df.to_json(f)\n",
    "    del history\n",
    "    del t\n",
    "    del v\n",
    "    del tx\n",
    "    del ty\n",
    "    del vx\n",
    "    del vy\n",
    "    del hist_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_dm_returns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
